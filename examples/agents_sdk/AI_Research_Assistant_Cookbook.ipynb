{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b66af9",
   "metadata": {},
   "source": [
    "# Building an **AI Research Assistant** with the OpenAI Agents SDK\n",
    "\n",
    "This notebook provides a reference patterns for implementing a multi‑agent AI Research Assistant that can plan, search, curate, and draft high‑quality reports with citations.\n",
    "\n",
    "While the Deep Research feature is avaialble in ChatGPT, however, individual and companies may want to implement their own API based solution for a more finegrained control over the output.\n",
    "\n",
    "With support for Agents, and built-in tools such as Code Interpreter, Web Search, and File Search, - Responses API makes building your own Research Assistant fast and easy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcd3942",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Overview](#overview)\n",
    "2. [Solution Workflow](#workflow)\n",
    "3. [High‑Level Architecture](#architecture)\n",
    "4. [Agent Definitions (Pseudo Code)](#agents)\n",
    "    * Research Planning Agent\n",
    "    * Web Search Agent\n",
    "    * Knowledge Assistant Agent\n",
    "    * Report Creation Agent\n",
    "    * Data Analysis Agent (optional)\n",
    "    * Image‑Gen Agent (optional)\n",
    "5. [Guardrails & Best Practices](#best-practices)\n",
    "6. [Risks & Mitigation](#risks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e358e",
   "metadata": {},
   "source": [
    "### 1 — Overview <a id='overview'></a>\n",
    "The AI Research Assistant helps drives better research quality and faster turnaround for knowledge content.\n",
    "\n",
    "1. **Performs autonomous Internet research** to gather the most recent sources.\n",
    "2. **Incorporates internal data sources** such as a Company's proprietery knowledge sources. \n",
    "3. **Reduces analyst effort from days to minutes** by automating search, curation and first‑draft writing.\n",
    "4. **Produces draft reports with citations** and built‑in hallucination detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb6ce3",
   "metadata": {},
   "source": [
    "### 2 — Solution Workflow <a id='workflow'></a>\n",
    "The typical workflow consists of five orchestrated steps: \n",
    "\n",
    "| Step | Purpose | Model |\n",
    "|------|---------|-------|\n",
    "| **Query Expansion** | Draft multi‑facet prompts / hypotheses | `gpt‑4o` |\n",
    "| **Search‑Term Generation** | Expand/clean user query into rich keyword list | `gpt‑4o` |\n",
    "| **Conduct Research** | Run web & internal searches, rank & summarise results | `gpt‑4o` + tools |\n",
    "| **Draft Report** | Produce first narrative with reasoning & inline citations | `o1` / `gpt‑4o` |\n",
    "| **Report Expansion** | Polish formatting, add charts / images / appendix | `gpt‑4o` + tools |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4e6dc",
   "metadata": {},
   "source": [
    "### 3 — High‑Level Architecture <a id='architecture'></a>\n",
    "The following diagram groups agents and tools:\n",
    "\n",
    "* **Research Planning Agent** – interprets the user request and produces a research plan/agenda.\n",
    "* **Knowledge Assistant Agent** – orchestrates parallel web & file searches via built‑in tools, curates short‑term memory.\n",
    "* **Web Search Agent(s)** – perform Internet queries, deduplicate, rank and summarise pages.\n",
    "* **Report Creation Agent** – consumes curated corpus and drafts the structured report.\n",
    "* **(Optional) Data Analysis Agent** – executes code for numeric/CSV analyses via the Code Interpreter tool.\n",
    "* **(Optional) Image‑Gen Agent** – generates illustrative figures.\n",
    "\n",
    "Input/output guardrails wrap user prompts and final content for policy, safety and citation checks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3464739",
   "metadata": {},
   "source": [
    "### 4 — Pre-requisites <a id='pre-requisites'></a>\n",
    "\n",
    "Create a virual environment  \n",
    "\n",
    "Install dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a16ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai openai-agents --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69135215",
   "metadata": {},
   "source": [
    "### 5 — Agents (Pseudo Code) <a id='agents'></a>\n",
    "Below are skeletal class definitions illustrating how each agent’s policy and tool‑usage might look."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f3062e",
   "metadata": {},
   "source": [
    "#### Step 1 - Query Expansion\n",
    "\n",
    "The query expansion step ensures the subsequent agents conducting research have sufficient context of user's inquiry. \n",
    "\n",
    "The first step is to understand user's intent, and make sure the user has provided sufficinet details for subsequent agents to search the web, build a knowledge repository, and prepare a deepdive report. The `query_expansion_agent.py` accomplishes this with the prompt that outlines minimum information needed from the user to generate a report. This could include timeframe, industry, target audience, etc. The prompt can be tailored to the need of your deepresearch assistant. The agent will put a `is_task_clear` yes or no, when its no, it would prompt the user with additional questions, if sufficent information is available, it would output the expanded prompt. \n",
    "\n",
    "This is also an opportunity to enforce input guardrails for any research topics that you'd like to restrict the user from reserarching based on your usage policies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2618f60",
   "metadata": {},
   "source": [
    "##### Input Guardrails with Agents SDK \n",
    "Let's assume our ficticious guardrail is to prevent the user from generating a non-AI releated topic report. For this we will define a guardrail agent. The guardrail agent `topic_guradrail.py` checks whether the topic is related to AI, if not, it raises an execption. The function `ai_topic_guardrail` is passed to the `QueryExpansionAgent()` as `input_guardrails`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "620f9e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚫 Guardrail tripped – not an AI topic: The request is about trends in the luxury goods market, which is not focused on artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "from ai_research_assistant_resources.agents_tools_registry.query_expansion_agent import QueryExpansionAgent\n",
    "from agents import InputGuardrailTripwireTriggered\n",
    "\n",
    "query_expansion_agent_guardrail_check = QueryExpansionAgent()\n",
    "\n",
    "try:\n",
    "\n",
    "    result = await query_expansion_agent_guardrail_check.task(\"Write a research report on the latest trends in luxury goods market\")\n",
    "\n",
    "except InputGuardrailTripwireTriggered as e:\n",
    "    reason = e.guardrail_result.output.output_info.reasoning\n",
    "    #            └─────┬─────┘\n",
    "    #            GuardrailFunctionOutput\n",
    "    print(\"🚫 Guardrail tripped – not an AI topic:\", reason)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77364239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The task is not clear. The agent asks:\n",
      " Could you please specify the timeframe you have in mind for the research report (e.g., current year, last 5 years, or another period)? Additionally, should the report focus on any specific geographic region or subfields within AI developments (e.g., machine learning, natural language processing) or cover the topic broadly?\n",
      "\n",
      "\n",
      "user input:  within the last 1 year, in the US and around ehtical AI development \n",
      "\n",
      "Expanded query:\n",
      " Draft a research report that examines the latest trends in ethical AI development within the United States over the last year, providing an analysis of emerging practices, challenges, and regulatory considerations unique to this timeframe and region.\n"
     ]
    }
   ],
   "source": [
    "from ai_research_assistant_resources.agents_tools_registry.query_expansion_agent import QueryExpansionAgent\n",
    "\n",
    "query_expansion_agent = QueryExpansionAgent()\n",
    "\n",
    "# Initial prompt to the agent\n",
    "prompt: str = \"Draft a research report on the latest trends in AI developments\"\n",
    "expanded_query = \"\" \n",
    "\n",
    "try: \n",
    "\n",
    "    while True:\n",
    "        # Execute the agent with the current prompt\n",
    "        result = await query_expansion_agent.task(prompt)\n",
    "\n",
    "        # When the task is clear, show the expanded query and exit.\n",
    "        if result.is_task_clear == \"yes\":\n",
    "            expanded_query = result.expanded_query\n",
    "            print(\"\\nExpanded query:\\n\", expanded_query)\n",
    "            break\n",
    "\n",
    "        # Otherwise, display the clarifying questions and ask the user for input.\n",
    "        print(\"\\nThe task is not clear. The agent asks:\\n\", result.questions)\n",
    "        prompt = input(\"Please provide the missing details so I can refine the query: \")\n",
    "        print(\"\\n\")\n",
    "        print(\"user input: \", prompt)\n",
    "        \n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Non-AI topic guardrail tripped!\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b10e7",
   "metadata": {},
   "source": [
    "#### Step 2 - Web Search Terms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725969cb",
   "metadata": {},
   "source": [
    "Conducting Web search is typically an integral part of the deep research process. First we generate web search terms relevant to the research report. In the next step we will search the web and build a knowledge repository of the data.\n",
    "\n",
    "The `WebSearchTermsGenerationAgent` takes as input the the expanded prompt, and generates succient search terms. You can structure the search term generation prompt according to your user's typical requirements such as include adjacent industries in the search terms, include competitors, etc. Additionally, you can also control how much data you want to gather e.g., number of search terms to generate. In our case, we will limit to 3 search terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15e0c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Ethical AI development trends USA 2025\n",
      "2. Challenges in AI ethics and regulations in 2025\n",
      "3. Emerging AI practices and legal considerations in the US 2025\n"
     ]
    }
   ],
   "source": [
    "placeholder_query = \"Draft a research report that examines the latest trends in ethical AI development within the United States over the last year, providing an analysis of emerging practices, challenges, and regulatory considerations unique to this timeframe and region.\"\n",
    "\n",
    "from ai_research_assistant_resources.agents_tools_registry.web_search_terms_generation_agent import WebSearchTermsGenerationAgent\n",
    "\n",
    "search_terms_agent = WebSearchTermsGenerationAgent(3)\n",
    "\n",
    "result = await search_terms_agent.task(placeholder_query)\n",
    "\n",
    "search_terms_raw = result\n",
    "\n",
    "for i, query in enumerate(search_terms_raw.Search_Queries, start=1):\n",
    "    print(f\"{i}. {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feeaae8",
   "metadata": {},
   "source": [
    "#### Step 3 - Scroll the Web build a inventory of data sources \n",
    "\n",
    "We will use custom web search to identify and knowledge content to form the baseline for our report. You can learn more about building custom web search and retreival here. [Building a Bring Your Own Browser (BYOB) Tool for Web Browsing and Summarization](https://cookbook.openai.com/examples/third_party/web_search_with_google_api_bring_your_own_browser_tool). You will also need a Google Custom Search API key and Custom Search Engine ID (CSE ID) in a .env file at the root. \n",
    "\n",
    "NOTE: The reason for using custom web search is provide more finegrained control over which information is retreived, and guardrails such as excluding competitor's content from your report. \n",
    "\n",
    "This is a 3 step process: \n",
    "\n",
    "1. Obtain the search results (top 10 pages)\n",
    "2. Scroll the pages, and summarize the key points \n",
    "3. Output guardrails to weedout irrelevant or undesirable results (e.g., the timeframe of the content doesn't align with user's need, or mentions a competitor)\n",
    "\n",
    "prerequisite pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b7260c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Ethical AI development trends USA 2025\n",
      "2. Challenges in AI ethics and regulations in 2025\n",
      "3. Emerging AI practices and legal considerations in the US 2025\n",
      "Results written to research_results.json\n"
     ]
    }
   ],
   "source": [
    "from ai_research_assistant_resources.utils.web_search_and_util import get_results_for_search_term\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "api_key = os.getenv('API_KEY')\n",
    "cse_id = os.getenv('CSE_ID')\n",
    "\n",
    "if not api_key or not cse_id:\n",
    "    raise ValueError(\"API_KEY and CSE_ID must be set as environment variables or in a .env file\")\n",
    "\n",
    "research_results = []\n",
    "\n",
    "for i, query in enumerate(search_terms_raw.Search_Queries, start=1):\n",
    "    print(f\"{i}. {query}\")\n",
    "    results =  get_results_for_search_term(query)\n",
    "    research_results.append(results)\n",
    "\n",
    "# Pretty-print the JSON response (or a friendly message if no results).\n",
    "if results:\n",
    "    # Write results to a file\n",
    "    with open(\"research_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(research_results, f, indent=2, ensure_ascii=False)\n",
    "    print(\"Results written to research_results.json\")\n",
    "else:\n",
    "    print(\"No results returned. Check your API credentials or search term.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9758743",
   "metadata": {},
   "source": [
    "### Step-4: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a890c80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "255e0a06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb69c797",
   "metadata": {},
   "source": [
    "### 5 — Guardrails & Best Practices <a id='best-practices'></a>\n",
    "* **Crawl → Walk → Run**: start with a single agent, then expand into a swarm. \n",
    "* **Expose intermediate reasoning** (“show the math”) to build user trust. \n",
    "* **Parameterise UX** so analysts can tweak report format and source mix. \n",
    "* **Native OpenAI tools first** (web browsing, file ingestion) before reinventing low‑level retrieval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eed7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_KEY and CSE_ID are:  AIzaSyCQH3GUXJwnqOmvBp9U12P54eScvMJLH7c 50c7decc940664df9\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "An asyncio.Future, a coroutine or an awaitable is required",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m\n",
      "\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAPI_KEY and CSE_ID are: \u001b[39m\u001b[33m\"\u001b[39m, api_key, cse_id)\n",
      "\u001b[32m     18\u001b[39m nest_asyncio.apply()\n",
      "\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m results = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_results_for_search_term\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAI Trends\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Pretty-print the JSON response (or a friendly message if no results).\u001b[39;00m\n",
      "\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m results:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace-28/openai-cookbook/.venv/lib/python3.13/site-packages/nest_asyncio.py:28\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n",
      "\u001b[32m     26\u001b[39m loop = asyncio.get_event_loop()\n",
      "\u001b[32m     27\u001b[39m loop.set_debug(debug)\n",
      "\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m task = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mensure_future\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loop.run_until_complete(task)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:742\u001b[39m, in \u001b[36mensure_future\u001b[39m\u001b[34m(coro_or_future, loop)\u001b[39m\n",
      "\u001b[32m    740\u001b[39m         should_close = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[32m    741\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m742\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mAn asyncio.Future, a coroutine or an awaitable \u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[32m    743\u001b[39m                         \u001b[33m'\u001b[39m\u001b[33mis required\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m    746\u001b[39m     loop = events.get_event_loop()\n",
      "\n",
      "\u001b[31mTypeError\u001b[39m: An asyncio.Future, a coroutine or an awaitable is required"
     ]
    }
   ],
   "source": [
    "from ai_research_assistant_resources.utils.web_search_and_util import get_results_for_search_term\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "api_key = os.getenv('API_KEY')\n",
    "cse_id = os.getenv('CSE_ID')\n",
    "\n",
    "if not api_key or not cse_id:\n",
    "    raise ValueError(\"API_KEY and CSE_ID must be set as environment variables or in a .env file\")\n",
    "else:\n",
    "    print(\"API_KEY and CSE_ID are: \", api_key, cse_id)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "results = asyncio.run(get_results_for_search_term(\"AI Trends\"))\n",
    "\n",
    "# Pretty-print the JSON response (or a friendly message if no results).\n",
    "if results:\n",
    "    print(json.dumps(results, indent=2))\n",
    "else:\n",
    "    print(\"No results returned. Check your API credentials or search term.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdcab82",
   "metadata": {},
   "source": [
    "### 6 — Risks & Mitigation <a id='risks'></a>\n",
    "| Pitfall | Mitigation |\n",
    "|---------|------------|\n",
    "| Scope‑creep & endless roadmap | Narrow MVP & SMART milestones | fileciteturn1file4L23-L24 |\n",
    "| Hallucinations & weak guardrails | Golden‑set evals, RAG with citation checks | fileciteturn1file4L25-L26 |\n",
    "| Run‑away infra costs | Cost curve modelling; efficient models + autoscaling | fileciteturn1file4L27-L28 |\n",
    "| Talent gaps | Upskill & leverage Agents SDK to offload core reasoning | fileciteturn1file4L29-L30 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b40dcf3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
